{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Women in STEM workforce: Predict income and field of work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is in this notebook?\n",
    "\n",
    "We have looked at the STEM gender pay gap over the years in the EDA notebook of the same folder. Even though women has taking up bigger part among the jobs between the years of 2003 and 2013, women's salaries remain 40% lower than men's in average! The analysis also shows how the gender gap compare to one another in the various fields in STEM areas. \n",
    "\n",
    "In this notebook, I will explore using machine learning models to predict the income and principal job field given other aspects of the data. It would answer the question of what kind of pay and what types of job would a STEMer expect to receive in the work force."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Modules and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import important stuff\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import visulization modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import stats modules\n",
    "from scipy.stats import ttest_ind, chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sklearn modules\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the data from csv file with a series of NAN values \n",
    "df1 = pd.read_csv('./../data/highered_00004.csv', dtype={'REFID': str},na_values=[96, 99, 98, 9996, 9998 ,\n",
    "    9999, 999996, 999998, 999999, 9999998, 9999999] )\n",
    "df1 = df1.drop(['REFID'], axis=1)\n",
    "df2 = pd.read_csv('./../data/highered_00007.csv', dtype={'REFID': str},na_values=[96, 99, 98, 9996, 9998 ,\n",
    "    9999, 999996, 999998, 999999, 9999998, 9999999] )\n",
    "df3 = pd.read_csv('./../data/highered_00008.csv', dtype={'REFID': str},na_values=[96, 99, 98, 9996, 9998 ,\n",
    "    9999, 999996, 999998, 999999, 9999998, 9999999] )\n",
    "\n",
    "# merge the data frames containing different features\n",
    "dfm = df1.merge(df2,  on=['PERSONID', 'YEAR', 'WEIGHT', 'SAMPLE', 'SURID'])\n",
    "df = dfm.merge(df3, on=['PERSONID', 'YEAR', 'SURID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the survey \n",
    "\n",
    "https://highered.ipums.org/highered/survey_designs.shtml\n",
    "\n",
    "This notebook will only consider the entries with a job. So the labor force status was chosen in the next cell and some irrelevent or heavily missing data columns were removed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop columns with irrelevant or many missing data\n",
    "df_employed = df[df['LFSTAT']==1]\n",
    "df_employed_small = df_employed.drop(['CTZUS', 'WEIGHT', 'WRKG', 'NRREA','FNVS', 'CHTOT', 'CPI2009C', 'PERSONID', 'LFSTAT','BA03Y5', 'LOOKWK'], axis=1)\n",
    "df_employed_l = df_employed_small.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEAR', 'SAMPLE', 'SURID', 'AGE', 'BIRYR', 'GENDER', 'MINRTY', 'RACETH',\n",
       "       'BTHUS', 'CTZUSIN', 'NBAMED', 'NBAMEMG', 'DGRDG', 'HD03Y5', 'NDGMED',\n",
       "       'NDGMEMG', 'HRSWKGR', 'WKSWKGR', 'OCEDRLP', 'NOCPR', 'NOCPRMG',\n",
       "       'SALARY', 'JOBSATIS', 'EMSEC', 'EMSIZE', 'GOVSUP', 'WAPRSM', 'ACTCAP',\n",
       "       'ACTDED', 'ACTMGT', 'ACTRD', 'ACTRDT', 'ACTRES', 'ACTTCH', 'WKTRNI',\n",
       "       'WAPRI', 'WASEC', 'WASCSM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_employed_l.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations Overviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick check, I take a look at the Pearson correlation coefficient of Salary column and the rest of columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top correlated:\n",
      "SALARY     1.000000\n",
      "HRSWKGR    0.403946\n",
      "DGRDG      0.263496\n",
      "GENDER     0.257586\n",
      "EMSEC      0.215927\n",
      "SURID      0.193761\n",
      "Name: SALARY, dtype: float64\n",
      "Top reverse correlated:\n",
      "ACTTCH   -0.183005\n",
      "WAPRI    -0.172204\n",
      "HD03Y5   -0.167808\n",
      "BIRYR    -0.162161\n",
      "WASCSM   -0.141206\n",
      "Name: SALARY, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Top correlated:')\n",
    "print(df_employed_l.corr()['SALARY'].sort_values(ascending=False).head(6))\n",
    "print('Top reverse correlated:')\n",
    "print(df_employed_l.corr()['SALARY'].sort_values(ascending=True).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets interesting already! We see the top five positively correlated features include full time job status (HRSWKGR: hours worked per week), degree (DGRDG and SURID), gender, and employer sector (EMSEC). \n",
    "\n",
    "I would like to point out gender apparently made it to the top three correlated feature deciding a salary: being a man is likely to receive a higher pay than woman. This is another indicator of the pay disprancy between genders. Another insight from this is how the employer sector is playing an important role. The expected pay is lowest if working in a school system, higher if working for the govenment, and highest if working for business and industry.\n",
    "\n",
    "Among the top negatively correlated columns, the first place goes to teaching as prime job activity. Other columns also more or less has teaching in its reason for making the list (expect for birth year). This resonates with the discovery from the positively correlated employer sector. This gives a supporting evidence of how teachers or people who teach are given lower compensation among jobs, for the ongoing teacher strike across the country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Salary Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target column preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I change salary from a numeric column to a catagorical column. Due to privacy reason, the survey on scientists and engineers provided by Higher Education do not contain location data. As common knowledge tells us, the location could be a large factor in deciding how much a person is getting paid. The cost of living of San Francisco is more than two times that of Omaha, as an example. It is only fair that people in high cost of living areas get better paid than people in low cost of living places. Since this crucial piece of information is missing, it adds a lot of uncertainty into the prediction of the salary. \n",
    "\n",
    "To make the task practical, I am going to predict the salary level (low or high), instead of the exact number. \n",
    "\n",
    "I have also done some work that looks into the prediction of numeric salary using several regression models. It gave limited the accuracy scores due to above reasons. Please find the details in regression notebook in the same folder if interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function change the salary column to a salary level column\n",
    "def salary_bracket(ls):\n",
    "    new_s = np.empty(len(ls))\n",
    "    for i,s in enumerate(ls):\n",
    "        if s<60000:\n",
    "            new_s[i] = 0\n",
    "        else:\n",
    "            new_s[i] = 1\n",
    "    return new_s\n",
    "\n",
    "# define a dataframe only contains salary that is larger than 0 (eliminate the entry fault)\n",
    "df_employed_clf =[]\n",
    "df_employed_clf = df_employed_l[(df_employed_l['SALARY']>0)]\n",
    "\n",
    "\n",
    "\n",
    "new_salary = salary_bracket(df_employed_clf['SALARY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a new dataframe that is similar to the previous one except for it contains only the salary level column. Note the birth year column (BIRYR) is a dependent variable on YEAR and AGE. This column is dropped blow. Some major groups columns is also dependent on the other columns in the survey data, they will be dropped as well. \n",
    "\n",
    "In the meantime, we choose the part of the data considering only full time jobs (hours per week >=36)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_employed_nod = []\n",
    "df_employed_nod = df_employed_clf.assign(salary_d=pd.Series(new_salary).values)\n",
    "df_employed_nod.salary_d = df_employed_nod.salary_d.astype('category')\n",
    "df_employed_nod=df_employed_nod.drop(['SALARY'], axis=1)\n",
    "df_employed_nod=df_employed_nod.drop(['BIRYR','NBAMEMG','NDGMEMG','NOCPRMG'], axis=1)\n",
    "df_employed_nod=df_employed_nod[(df_employed_nod['HRSWKGR']==3) | (df_employed_nod['HRSWKGR']==4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at the distribution of the pay between men and women. Much more men were paid above 60k income than women while the count of women and men paid below 60k remain similar. This also gives that more entries report higher than 60k salary than below 60k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.tight_layout>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm0AAAFXCAYAAADwAnnoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucXVV5+P9PuCWESwGpUZSIPytPMEqFVEHxArRWLpUi\nohgQBBFFIVDANOINoUCENhSxcpESFBC8lK8EVC5qACslUGIRDfg0LVJESVAiaAgDgczvj7WGHI6T\nMCfMmZk9+bxfr3nNOftZe+21D+ycZ9Zl7zG9vb1IkiRpZFtnuBsgSZKk52bSJkmS1AAmbZIkSQ1g\n0iZJktQAJm2SJEkNYNImSZLUAOsNdwMkDa6IeDNwDLAz8ELgIeB64NTMvG8Ijr8rcCOwXWb+fBDr\n3Qb4Rdvmp4HfAN8H/j4zHxys462mHcP6+Upae9nTJo0iEXEscBPl2j4OeBtwEiXBuCMi/mz4Wjdo\njgPeUH/eCvw95TyviYgx3TzwWvL5Shqh7GmTRomImALMovT4nNQS+mFEfB2YD5wGHDAc7RtEP8/M\neS3vb4mI5cAVwE7AvP53e37Wos9X0ghl0iaNHh8D7gNObQ9k5mMRcTLwutbtEXEYMAN4OfC/wEmZ\n+c0a24YyHLk3cALwRspQ4OmZeUFLHbsAZwGvAe4CvtR+/Ij4G+AfgO2AXwOzMvOLLfFe4OPA4cCL\ngXdk5k0dnPud9ffLgHkRsRklgfpbyhDmb4GvU4ZQl0fEXcCCzJza0oaXA/cCb83MH/ZzjI4+34gY\nS+mFOwDYGngU+A5wTGb+vuXz3Z/SW7g9cDfwscy8sYNzl7SWcHhUGj32AuZk5vL+gpl5RWYe3/c+\nIj4E/CtwNbAPcAPw9Yh4R9uuFwM/oCRvtwDnR8Srah0vB75HSebeBVwLfLF154jYA5gD/JiSRH0Z\n+HxEHNV2nE9REq0jgds7OXHglfX3ffX3FZShy+OAPeox/w44tMYvBd4REeNb6ngvcD/w76s4Rkef\nL3A2JQk9Bfhr4EzgQEqS3Ooi4GZgP2ARcG1ExCraIGktZk+bNApExBbAppTestbt69D2x1lmPlW3\nnwJcmJl/X0PXR8QLKD1i17TscnFmnl7ruw14N7AnpVdoGvA74F2Z+SQl4dgSOLpl/1OA72Xm4S3H\nWR/4bER8qSUJujozvzKA010nIvr+7doQ2BH4R0pv239GxIaUf9s+3NJjNTci9gbeBFwIXA58DngH\npQcOYCpwRWb+0QOZO/1868stgeMy8/L6/qaIeFNtQ6ur+v4bRMQPKL19xwIfHcBnIWktYtImjQ59\niUP7RPwzKUObz4iI7Wq5CcB1LQkQwHXA+2qS0ue2vhd1GPB3wEZ10y7AD2rC1udb1KQtIjYC/gI4\nru0411N61l4N/Fdf9QM4TyhDjO1uB96fmSuAx4G3RcSYiHgFEJShxwnABvU8fhURN1J6174eEZMp\nw7vvW8UxO/p8M/Pnmfnu+n5rYFI911dRhmpbfa3vRWY+GRHXUT5XSXoWkzZpdHiYkqxMbNt+NiuT\nginA+fX1C+rvb62ivhcBy+rrx9tiK1iZxGzOHychi1teb05JdM6uP+1ezMqk7aFVtKXdMcCt9fVy\n4FeZ+aw2RMS+wOcpn8fiWv5xnp10XUYZ6t2U0sv2s8y8axXH7PTzpfaqXUBJ1JYA/0n5TNsTv/bb\nlPyG8rlJ0rOYtEmjQGb21h6ad0TEx/uG+DLzAeABgIjYuGWXR+rvw4Cf9VPlLyg9U89lCWWif6vW\nXrpH6+9PUOa+tfufARyj3cLMvGNVwYh4JWXI81zgjMxcVLff1lb0ylpmT8p8sktWVWenn29E/All\niPl6YK/M/L+6/euUxRKttmh7/0JK4iZJz+JCBGn0OBPYljLs2J/tWl7/nJJwvSgz7+j7oQwjnkjp\nTRuIm4G3t03o36PvRWb+Afgp8LK247wQOBkYN8DjdGJHyjDozJaEbQJl+POZf/Nq2+ZQhnInURYv\nrE4nn+8kYDPgrJaEbUPKsGf7v7t79b2oK073BPpbvSppLWdPmzRKZOa8iDga+EK9DcellF6grSnD\nf3tRkoEH62KE04FT66KAHwF/DpwOXJaZTwxwAePZwIeAb0fEP1HmbbWvCj2ZMm9sKWV16TbAGcCP\n+5KqQXYn5UkJsyJiNrAV8ElKgrhRW9lLKXPkftSXXK1KJ58vZRXoUuCU+rn8CeWWIVuxsvexzzER\nsaS2+5jaxrPW4LwljXL2tEmjSGaeD7yekjicTrmNxyzgKeCdwK6Z+WgtOws4njL5/jrKLTFm8cdJ\n1+qO9yCwG+UPwCtrXdPaylxJmfD/V8B3KatJv0a5P9mgy8ykDPu+oR7vZEqP2mnA6yJi3ZbiP6B8\nNl8dYN0D+nwz8xHKKtuXUIZJzwJ+Qvlstm1b6DGD8llcCYyvdfyy8zOXNNqN6e39o9XtkrRWqPeQ\nuwp4cWb+boiPvQ1l7uCemXndUB5bUjM5PCpprRMRO1Pmjh0OXDrUCZskrQmHRyWtjTalDA3fS3l8\nliSNeA6PSpIkNYA9bZIkSQ1g0iZJktQALkRYQ/Pnz++dMmXKcDdDkqSh0v4INg0xe9okSZIawKRN\nkiSpAUzaJEmSGsCkTZIkqQFciCBJkgbNgZ+5cUhuAHv5KbsNeGFERHwKmA48Dmydmcu71a6WR9Rt\nkplLB7NukzZJkjTaHQYcl5mzh7shz4dJmyRJGrUiIoGXA1+MiB2BBZTH2G0B/BD4SGYuiohdgbOA\n7wNHAI8BHwH+EjgUeAQ4PDN/EBHrACcD7wZeUmOnZuYF/Rz/NcAXgNcCvwRmZOZ31+RcnNMmSZJG\nrcwM4H5KgnUzcCKwLyXZuhf4ekvxHYCHgBcAXwa+Bfwf8KfAFcDnarmDgHcBu1KeZfxx4OyI2Lj1\n2BGxCXAD8A1gS2AacFlEbLsm52LSJkmS1haHA/+cmQsys4eSwO3UkkQtB87OzBXAjcDTwOfrHLjv\nAS+r5eYAuwOLKclfDzCO0nvXam/gocw8NzOfysyb6r6HrknjHR6VJElri4nAqRFxUsu2Xkoythz4\nQ2Y+Vbc/Xd+vqO9XsLKza33gHOCvKL14d9bt7Z1hE4FXRcQjLdvWA/7fmjTepE2SJK0tHgT+qXVB\nQkRsB/wv8EZKAjcQMykJ2laZ2RMRE4H3r+J4t2bmW1qO91LKKtaOmbRJkqS1xVeAGRHxQ8p8tqOA\nU4FtOqxnU8qQ6FMR8QLgn+r29Sk9dn2+A8yKiKmUeW3bUhY6fAa4qNPGm7RJkobMjJtOGO4mjHpn\n7DpruJswkl1KmXd2LTAB+Dmwd2b+LiI6qeczwCXA7ygrRy+l9NZtB9zVVygzl0TEHsDZwHnAUuC8\nzOw4YQMY09s7JPfAG3Xmz5/fO2XKlOFuhiQ1iklb93UxaRvwzWzVHa4elSRJagCTNkmSpAYwaZMk\nSWoAkzZJkqQGMGmTJElqAJM2SZKkBjBpkyRJagCTNkmSpAYwaZMkSWqAYXmMVUS8HrgqM7eq7zcA\nZgFTKXdc/hbw0cx8MiLGAKcDH6ztvQQ4PjOfrvtOBU6jPI7iRuDwzFxcYzsAFwCTgYXAkZk5r8Y2\nB2YDuwOPAiev6WMlJElSMeOmE4bkUUtn7DpryJ/QEBG9wGsy82dDfWwY4p62iBgTER8AbgA2aAnN\npCRW2wKvrK8/VmNHAXsD21Oe6bULcEKtb3vgfEqytyWwCLi4xsYB19T3mwHnAFdHxMa13gspzwCb\nAOwPnBkROw/6SUuSJA2Coe5p+wTwHkrP2AyAiFgf+BCwU2YuqdveBaxf9zkYODszH6yxmcA/AGcC\nBwFzMvO2GpsB/CYiJgA7Aisy87xaz+yIOA7YKyK+C+wLbJuZPcDtEXE5cAgwr5sfgCRJGloRsQ1w\nB2Xk7uOUTqsZwAuB44GnKaN4l0fEMcARwESgh/KA98/2U+dE4F8onUlLgNMz8+JunsdQJ22zKR/Y\nW1u2vbK2Y6eImAOMBy6nJHgAk4C7W8onEHXYdBJw6zOBzIcjYgkQ/ezXt+8kylDp8sy8ty22Xycn\n09PT00lxSZK6rlvfTePGjetKvUPoBcDLgJcAh1KmT50DbEWZgvX5iPgl8EngTZm5MCLeDNwcEZdl\n5v/0VRQR61JG875LGa3bDrg2Iu7LzBu7dQJDmrS19Ja1bt6CMlT6DuB1wCbAtynzzE4FNgKWtZRf\nRsmQx/YT64uPH0Ds8VXEBmzBggWdFJckqeu69d00ZcqUrtQ7xM7KzOURMRdYt+X99cC5wHxgSmY+\nUEftNqDkC1sB/9NSz+soPXGfzMwVwE8i4gJKD93oSNpW4QlKEvapzHwEeCQizgKmUZK2ZcCGLeXH\nA09lZk9EtMf64kv72a891v4nQ19swCZPntxJcUmSE1C6zu+m1VpSfz9dfz9Sf6+ov9cBPl2naT1E\nGVLt295qIrApsKSlI2pd4MeD3eBWIyFpW0j5sMa2bFuXsooU4B7KcOdt9X3Uba2xEojYktJzdw+l\nx+7otmMFZeh1IbBBREzMzPtbYu3Dqas1CrqKJUmjjN9Nq/VcK1uPB14NvCIzH63z7g/op9yDwK8y\nc2Lfhtoz19UVrcOetGXmIxFxFXB6vX3HRsBxwGW1yGXA9NqVuRw4Ebi0xq6gjDXPpmTDM4Fr69y2\nucDYiJhGWWF6MGWl6PWZ+VidPzczIo6grFY9ENhrCE5ZkiSNTJsCTwJP1rtNnEYZIl2/rdw8YFlE\nTAfOpuQX1wJXAZ/uVuNGys11DwV+Senpugv4HuW+bVDGmOcAt9f4LcBZAJl5J2X8eDalG3Mr4LAa\newLYk3I7kCWU4dZ9MvOxWu8RlP8IDwBXAtP7VqFKkqS10jnAU5ScYiFlKtUtlIUGz8jM5ZTbke1K\nud3YfGAucEo3Gzemt3dI7oE36syfP793lEzKlKQhM+OmE4a7CaPeGbvOeu5Ca2bIb2arZxspPW2S\nJElaDZM2SZKkBjBpkyRJagCTNkmSpAYwaZMkSWoAkzZJkqQGMGmTJElqAJM2SZKkBjBpkyRJagCT\nNkmSpAYwaZMkSWoAkzZJkqQGMGmTJElqAJM2SZKkBjBpkyRJagCTNkmSpAYwaZMkSWoAkzZJkqQG\nMGmTJElqAJM2SZKkBlhvOA4aEa8HrsrMrdq2rwP8AJifmR+r28YApwMfpLT3EuD4zHy6xqcCpwET\ngBuBwzNzcY3tAFwATAYWAkdm5rwa2xyYDewOPAqcnJkXdfO8JUmS1tSQ9rRFxJiI+ABwA7BBP0VO\nAN7Stu0oYG9ge2A7YJdajojYHjgfmApsCSwCLq6xccA19f1mwDnA1RGxca33QmApJdnbHzgzInYe\nlBOVJEkaZEM9PPoJ4FhKz9iz1ATsMOBbbaGDgbMz88HMXATMBA6tsYOAOZl5W2Y+DswA9oiICcBu\nwIrMPC8zl2fmbGAxsFdN3PYFTsrMnsy8HbgcOGSQz1eSJGlQDPXw6GzKUOdbWzdGxFjKsOcR9afV\nJODulvdZdokxNXbrM4HMhyNiCRD97Ne37yTKUOnyzLy3LbZfJyfT09PTSXFJkrquW99N48aN60q9\nGrghTdoy80GAiGgPzQSuz8xbIqI9adsIWNbyfhmlh3BsP7G++PgBxB5fRWzAFixY0ElxSZK6rlvf\nTVOmTOlKvRq4YVmI0CoidqcsBnj9KoosAzZseT8eeCozeyKiPdYXX9rPfu2x9j8Z+mIDNnny5E6K\nS5LmDXcDRj+/m0avYU/agPcCrwAeqj1w44EVETEpM/8GuIcy3HlbLR91Gy2xEojYEtiibt8EOLrt\nWEGZu7YQ2CAiJmbm/S2x9uHU1bKrWJI00vjdNHoNe9KWmR8CPtT3PiK+DPy275YfwGXA9IiYCywH\nTgQurbErgJsjYjZwB2WY9do6t20uMDYiplFWmB5MWSl6fWY+FhFzgJl1OHYycCCwV3fPVpIkac00\n4ea65wJzgNspPWG3AGcBZOadlIULs4GHgK0oK1DJzCeAPSm3A1kCTAP2yczHar1HAOsDDwBXAtMz\ns683T5IkaUQZ09vbO9xtaKT58+f3OilTkjoz46YThrsJo94Zu87qVtVjulWxBqYJPW2SJElrPZM2\nSZKkBjBpkyRJagCTNkmSpAYwaZMkSWoAkzZJkqQGMGmTJElqAJM2SZKkBjBpkyRJagCTNkmSpAYw\naZMkSWoAkzZJkqQGMGmTJElqAJM2SZKkBjBpkyRJagCTNkmSpAYwaZMkSWoAkzZJkqQGMGmTJElq\nAJM2SZKkBjBpkyRJaoD1huOgEfF64KrM3Kq+fynwL8CbgeXAN4GPZeYTETEGOB34YG3vJcDxmfl0\n3XcqcBowAbgRODwzF9fYDsAFwGRgIXBkZs6rsc2B2cDuwKPAyZl50RCcviRJUseGtKctIsZExAeA\nG4ANWkKXAQ8ALwFeC7wO+HSNHQXsDWwPbAfsApxQ69seOB+YCmwJLAIurrFxwDX1/WbAOcDVEbFx\nrfdCYCkl2dsfODMidh70k5YkSRoEQz08+gngWErPGAARsQHwGHBqZvZk5iLgq8Aba5GDgbMz88Ea\nmwkcWmMHAXMy87bMfByYAewREROA3YAVmXleZi7PzNnAYmCvmrjtC5xUj3k7cDlwSFfPXpIkaQ0N\n9fDobMpQ51v7NmTmk5SetFbvAH5SX08C7m6JJRB12HQScGtLXQ9HxBIg+tmvb99JlKHS5Zl5b1ts\nv05Opqenp5PikiR1Xbe+m8aNG9eVejVwQ5q0ZeaDABHRb7wmYp+nJFbvq5s3Apa1FFtG6SEc20+s\nLz5+ALHHVxEbsAULFnRSXJKkruvWd9OUKVO6Uq8GblgWIvQnIjYELgVeA7w1Mx+qoWXAhi1FxwNP\nZWZPRLTH+uJL+9mvPdb+J0NfbMAmT57cSXFJ0rzhbsDo53fT6DUikraI2AK4jpI0vSEzl7SE76EM\nd97WV7xua4311bMlsEXdvglwdPuhKHPXFgIbRMTEzLy/JdY+nLpadhVLkkYav5tGr2FP2uqQ6P+j\nrPx8V2YubytyGTA9IuZSbgdyIqVHDuAK4OaImA3cQVmkcG2d2zYXGBsR0ygrTA+mrBS9PjMfi4g5\nwMyIOIJyS5ADgb26ea6SJElraiTcXPcNlIUJbwN+FxFL688Pa/xcYA5wO6Un7BbgLIDMvBM4grLA\n4SFgK+CwGnsC2JNyO5AlwDRgn8x8rNZ7BLA+5VYjVwLTM7OvN0+SJGlEGdPb2zvcbWik+fPn9zop\nU5I6M+OmE4a7CaPeGbvO6lbVY7pVsQZmJPS0SZIk6TmYtEmSJDWASZskSVIDmLRJkiQ1gEmbJElS\nA5i0SZIkNYBJmyRJUgOYtEmSJDWASZskSVIDmLRJkiQ1gEmbJElSA5i0SZIkNYBJmyRJUgOYtEmS\nJDWASZskSVIDmLRJkiQ1gEmbJElSA5i0SZIkNYBJmyRJUgOYtEmSJDXAesNx0Ih4PXBVZm5V328O\nzAZ2Bx4FTs7Mi2psDHA68MHa3kuA4zPz6RqfCpwGTABuBA7PzMU1tgNwATAZWAgcmZnznuuYkiRJ\nI82Q9rRFxJiI+ABwA7BBS+hCYCkl8dofODMidq6xo4C9ge2B7YBdgBNqfdsD5wNTgS2BRcDFNTYO\nuKa+3ww4B7g6IjYewDElSZJGlKEeHv0EcCylZwyAmkTtC5yUmT2ZeTtwOXBILXIwcHZmPpiZi4CZ\nwKE1dhAwJzNvy8zHgRnAHhExAdgNWJGZ52Xm8sycDSwG9hrAMSVJkkaUoR4enU0Z6nxry7ZXAssz\n896WbQnsV19PAu5ui0UdNp0E3PpMIPPhiFgCRD/79e07iTJUurpjDkhPT08nxSVJ6rpufTeNGzeu\nK/Vq4IY0acvMBwEionXzRsDjbUWXAeNb4svaYusAY/uJte77XLHVHXNAFixY0ElxSZK6rlvfTVOm\nTOlKvRq4YVmI0GYZ0J6+j6fMN+uLb9gWeyozeyKiPda673PFVnfMAZk8eXInxSVJ84a7AaOf302j\n14CTtoiYDRybmX9o2745cFFmdjS02GIhsEFETMzM+/uqZeXQ5j31/W0tsXvaYn1t2RLYom7fBDi6\n/TQoc9ee65gDYlexJGmk8btp9Fpt0hYRb6HMAQN4P7AgIv7QVmwS8Jdr2oDM/ENEzAFmRsQRlNtz\nHAjsVYtcBkyPiLnAcuBE4NIauwK4uSaUd1AWKVxb57bNBcZGxDTKCtODKStFr8/Mx57jmJIkSSPK\nc/W0PQJ8HBhTf44Fnm6J91KGFKc/z3YcQUmsHuirLzP7etbOpSRbt1PmsV0GnAWQmXfWpGs28CLg\n34HDauyJiNiz1ns68D/APpn52ACOKUmSNKKM6e3tHVDBiLgR2C8zf9fdJjXD/Pnze52UKUmdmXHT\nCcPdhFHvjF1ndavqMd2qWAMz4DltmbkbPPOEgvVo+4+XmU8ObtMkSZLUp5OFCH8BnAfs2BYaQxkm\nXXcQ2yVJkqQWndzy40LgD5QnCfy+O82RJElSfzpJ2iYB22fmwm41RpIkSf3r5NmjdwMv71ZDJEmS\ntGqd9LSdDXwpIj5PuTntsxYeZOYNg9kwSZIkrdRJ0vaV+ru/tcQuRJAkSeqiTm750clQqiRJkgaR\niZgkSVIDdHKfthWUYdB+ZabDo5IkSV3SyZy2PfvZ9xXAMcAnB61FkiRJ+iOdzGm7vr/tEXE3MBP4\n+mA1SpIkSc82GHPa7gdePQj1SJIkaRU6mdP21/1s3hQ4GvjJoLVIkiRJf6STOW3X9bPtSeA/gQ8P\nTnMkSZLUH+/TJkmS1ACd9LQREWOAvYFXUZ6A8HPg2szs6ULbJEmSVHUyp21r4NuU23wkJWl7JfCr\niNgtM3/VnSZKkiSpkyHPLwCLgImZOSUzXwu8DLgP+OcutE2SJElVJ0nbXwIfy8wlfRsy87fAdKC/\nlaWSJEkaJJ0kbb8HxvezfTywYnCaI0mSpP50shDhW8C5EXFIZi4AiIjXAF8E5jzfhkTEG4FzgG2B\nB4GTM/PyiNgcmA3sDjxat19U9xkDnA58sJ7LJcDxmfl0jU8FTgMmADcCh2fm4hrbAbgAmAwsBI7M\nzHnP9zwkSZK6oZOethOBh4G7ImJpRCwF7qTMaTvu+TQiItYFrgI+l5mbUpKwr0TENsCFwFJK4rU/\ncGZE7Fx3PYqymnV7YDtgF+CEWuf2wPnAVGBLyny8i2tsHHBNfb8ZJVm8OiI2fj7nIUmS1C0DTtoy\n8w/ADcDJwGHAgcBNwA8z85Hn2Y7NgD8F1qu9ZysoN+59GtgXOCkzezLzduBy4JC638HA2Zn5YGYu\nojwD9dAaOwiYk5m3ZebjwAxgj4iYAOwGrMjM8zJzeWbOBhYDez3P85AkSeqKTm758TlKknRkZl5T\nt20NnBgRm2bmKWvaiMx8OCLOBa4ALqMkk4dTesiWZ+a9rcWB/errScDdbbGoid8k4Na2YywBop/9\n+vad1Em7e3q8PZ0kaWTp1nfTuHHjulKvBq6TOW2HAAdk5r/3bcjML0bEPcBXgDVO2iJiHWAZ8G7g\nauBtlB61fYDH24ovY+WCiI3q+9bYOsDYfmKt+64uNmALFizopLgkSV3Xre+mKVOmdKVeDVwnSdvG\nwJJ+ti8CNn+e7dgP2Ckzp9f334mIbwOfBdpT+/GUOW5QEq0N22JPZWZPRLTHWvddXWzAJk+e3Elx\nSZLLvbrO76bRq5OkbS5wRkS8r28OW0RsSpnjdvPzbMdESu9Yq6eAHwNvjoiJmXl/3R6sHNq8p76/\nrSV2T1uM2tYtgS3q9k2Ao9uOF5TevQGzq1iSNNL43TR6dZK0TQO+T3lsVd8cs5cDv6AMYz4f3wNm\nRsRhwJeBtwDvpNzmY5saO4Jye44DWblg4DJgekTMBZZTVrheWmNXADdHxGzgDsoihWvr3La5wNiI\nmEZZYXowZXXq9c/zPCRJkrqik9WjvwReA7yHMoftQsotOP48M3/xfBqRmT+tdR1LuRfbF4H3Z+Yd\nwBHA+sADwJXA9Mzs61k7l3KPuNspvW+3AGfVOu+s+84GHgK2oqx6JTOfAPak3A5kCSUh3SczH3s+\n5yFJktQtY3p7e4e7DY00f/78XidlSlJnZtx0wnA3YdQ7Y9dZ3ap6TLcq1sB0cnNdSZIkDROTNkmS\npAYwaZMkSWoAkzZJkqQGMGmTJElqAJM2SZKkBjBpkyRJagCTNkmSpAYwaZMkSWoAkzZJkqQGMGmT\nJElqgPWGuwGSNBIc+Jkbh7sJa4Wtdx/uFkjNZU+bJElSA5i0SZIkNYBJmyRJUgOYtEmSJDWASZsk\nSVIDmLRJkiQ1gEmbJElSA5i0SZIkNcCIubluRLwUOB94C/B74MzMPCciNgdmA7sDjwInZ+ZFdZ8x\nwOnABynncglwfGY+XeNTgdOACcCNwOGZubjGdgAuACYDC4EjM3PeEJ2uJElSR0ZET1tNvq4C7gFe\nALwd+GxEvBG4EFhKSbz2B86MiJ3rrkcBewPbA9sBuwAn1Dq3pySBU4EtgUXAxTU2Drimvt8MOAe4\nOiI27va5SpIkrYkRkbQBOwFbAR/PzOWZuQB4A/ArYF/gpMzsyczbgcuBQ+p+BwNnZ+aDmbkImAkc\nWmMHAXMy87bMfByYAewREROA3YAVmXlePd5sYDGw15CcrSRJUodGyvDojsACSi/aQZTh0dOAu4Dl\nmXlvS9kE9quvJwF3t8Wi9txNAm59JpD5cEQsAaKf/fr2ndRJo3t6ejopLklS13Xru2ncuHFdqVcD\nN1KSti0ovV9zgYnAXwDXUYY+H28ruwwYX19vVN+3xtYBxvYTa913dbEBW7BgQSfFJUnqum59N02Z\nMqUr9WrgRkrS9gSwJDNn1vf/ERFXAicD7an9eMocNyiJ1oZtsacysyci2mOt+64uNmCTJ0/upLik\nkWzOrc9dRmoAv5tGr5GStCWwXkSs27fyE1gX+C/gLRExMTPvr9uDlUOb99T3t7XE7mmLlUDElpQe\nvXuATYCj29oQlPlyA2ZXsSRppPG7afQaKUnb9yi9XydFxCnA64F3Am8DtgFmRsQRlNtzHMjKBQOX\nAdMjYi4N8MD2AAATmElEQVSwHDgRuLTGrgBujojZwB2URQrX1rltc4GxETGNssL0YMrq1Ou7faKS\nJElrYkSsHq2rO3elJGsPUXq8jqn3TTsCWB94ALgSmJ6ZfT1r5wJzgNspvW+3AGfVOu+s+86udW4F\nHFZjTwB7Um4HsgSYBuyTmY91+VQlSZLWyJje3t7hbkMjzZ8/v9dJmdLoceBnbhzuJqwVtt7928Pd\nhFHvjF1ndavqMd2qWAMzInraJEmStHombZIkSQ1g0iZJktQAJm2SJEkNYNImSZLUACZtkiRJDWDS\nJkmS1AAmbZIkSQ1g0iZJktQAJm2SJEkNYNImSZLUACZtkiRJDWDSJkmS1ADrDXcDpKE246YThrsJ\na4Uzdp013E2QpFHFnjZJkqQGsKdthDnwMzcOdxNGva13H+4WSJLUOXvaJEmSGsCkTZIkqQFM2iRJ\nkhrApE2SJKkBTNokSZIaYMStHo2ICcBPgQ9k5rcjYnNgNrA78ChwcmZeVMuOAU4HPkg5l0uA4zPz\n6RqfCpwGTABuBA7PzMU1tgNwATAZWAgcmZnzhuxEJUmSOjASe9ouAl7Q8v5CYCkl8dofODMidq6x\no4C9ge2B7YBdgBMAImJ74HxgKrAlsAi4uMbGAdfU95sB5wBXR8TG3TwxSZKkNTWikraIOBJ4DPhl\nfb8xsC9wUmb2ZObtwOXAIXWXg4GzM/PBzFwEzAQOrbGDgDmZeVtmPg7MAPaoPXm7ASsy87zMXJ6Z\ns4HFwF5DcqKSJEkdGjHDoxGxLaWXbCfgx3XzK4HlmXlvS9EE9quvJwF3t8WiDptOAm59JpD5cEQs\nAaKf/fr2ndRJm3t6ejopLq1VvD6k4dGta2/cuHFdqVcDNyKStohYD7gUOCYzl0REX2gj4PG24suA\n8S3xZW2xdYCx/cRa911dbMAWLFjQSXFpreL1IQ2Pbl17U6ZM6Uq9GrgRkbQBnwbuzMxr27YvA9pT\n+/GUOW598Q3bYk9lZk9EtMda911dbMAmT57cSfGBmXPrc5eRGqAr10c3ee1plGjctacBGylJ2wHA\niyPigPp+U+BrwBnABhExMTPvr7Fg5dDmPfX9bS2xe9piJRCxJbBF3b4JcHRbG4IyX27A7CqWVs3r\nQxoeXnuj14hI2jLzWXPJIuI+4Oh6y4/XAjMj4gjK7TkOZOWCgcuA6RExF1gOnEgZZgW4Arg5ImYD\nd1AWKVxb57bNBcZGxDTKCtODKatTr+/eWUqSJK25EbV6dBWOANYHHgCuBKZnZl/P2rnAHOB2Su/b\nLcBZAJl5Z913NvAQsBVwWI09AexJuR3IEmAasE9mPjY0pyRJktSZEdHT1i4zt2l5vQR4zyrKPQ18\nqv70F/8G8I1VxO4C3vh82ypJkjQUmtDTJkmStNYzaZMkSWoAkzZJkqQGMGmTJElqAJM2SZKkBjBp\nkyRJagCTNkmSpAYwaZMkSWoAkzZJkqQGMGmTJElqAJM2SZKkBjBpkyRJagCTNkmSpAYwaZMkSWoA\nkzZJkqQGMGmTJElqAJM2SZKkBjBpkyRJagCTNkmSpAYwaZMkSWqA9Ya7AX0i4k3ALGAS8FvgzMy8\nICI2B2YDuwOPAidn5kV1nzHA6cAHKedyCXB8Zj5d41OB04AJwI3A4Zm5uMZ2AC4AJgMLgSMzc94Q\nna4kSVJHRkRPW03MrgY+D2wOvBuYGRF/BVwILKUkXvsDZ0bEznXXo4C9ge2B7YBdgBNqndsD5wNT\ngS2BRcDFNTYOuKa+3ww4B7g6Ijbu9rlKkiStiZHS0/Yy4DuZeXl9/+OIuBF4I7AvsG1m9gC3R8Tl\nwCHAPOBg4OzMfBAgImYC/wCcCRwEzMnM22psBvCbiJgA7AisyMzz6vFmR8RxwF7AN7p/upIkSZ0Z\nEUlbZt5JScCAZ3re3gzcBSzPzHtbiwP71deTgLvbYlGHTScBt7Yc4+GIWAJEP/v17Tupk3b39PR0\nUlxaq3h9SMOjW9feuHHjulKvBm5EJG2tIuJPKEOX8ynz0I5tK7IMGF9fb1Tft8bWAcb2E2vdd3Wx\nAVuwYEEnxaW1iteHNDy6de1NmTKlK/Vq4EZU0hYRLwe+DfwvcABlnlp7aj+eMscNSqK1YVvsqczs\niYj2WOu+q4sN2OTJkzspPjBzbn3uMlIDdOX66CavPY0Sjbv2NGAjJmmLiB2B64DLgI9l5oqIWAhs\nEBETM/P+vqKsHNq8p76/rSV2T1usr/4tgS3q9k2Ao9ubAFxOB+wqllbN60MaHl57o9eISNrq4oDr\ngFmZeUbf9sz8Q0TMoawkPYJye44DKQsGoCR40yNiLrAcOBG4tMauAG6OiNnAHcBM4No6t20uMDYi\nplFWmB5MWZ16fZdPVZIkaY2MiFt+AIcDfwp8OiKWtvycBhwBrA88AFwJTO9bEQqcC8wBbqf0vt0C\nnAXPLG44gnKPt4eArYDDauwJYE/K7UCWANOAfTLzsSE4V0mSpI6NiJ62zDydcpPcVXnPKvZ7GvhU\n/ekv/g1WcQuPzLyLcksRSZKkEW+k9LRJkiRpNUzaJEmSGsCkTZIkqQFM2iRJkhrApE2SJKkBTNok\nSZIawKRNkiSpAUzaJEmSGsCkTZIkqQFM2iRJkhrApE2SJKkBTNokSZIawKRNkiSpAUzaJEmSGsCk\nTZIkqQFM2iRJkhrApE2SJKkBTNokSZIawKRNkiSpAUzaJEmSGmC94W7AcIqIHYALgMnAQuDIzJw3\nvK2SJEn6Y2ttT1tEjAOuAS4GNgPOAa6OiI2HtWGSJEn9WGuTNmA3YEVmnpeZyzNzNrAY2GuY2yVJ\nkvRH1uakbRJwd9u2rNslSZJGlLV5TttGwLK2bcuA8QOtoKenZ1AbJI0mXh/S8OjWtTdu3Liu1KuB\nW5uTtmXAhm3bxgNLB1rBggULBrVBACf87aaDXqfaHTjcDVgrdOP66CavvaHi9ddtXbz2eqdMmTKm\nW5Xrua3NSds9wNFt2wK4fCA7+z+uJEkaSmtz0jYXGBsR04DzgYOBCcD1w9oqSZKkfqy1CxEy8wlg\nT2AqsASYBuyTmY8Na8MkSZL6Maa3t3e42yBJkqTnsNb2tEmSJDWJSZskSVIDmLRJbSJi14jYbLjb\nIa0NImLf4W6D1BTOaZOqiHg58M+UR5z9BvjnzPzi8LZKGp0i4gBgBrAdcCvwd5l51/C2ShrZTNo0\npCKiF3hNZv6sbft9wNGZ+e0O63s18NPMfN73zYuI+cB/AE8C84B/Bd6Vmd+PiDHAZ4AjKTdlngt8\nIDMfqfv+HTAd2AS4GvhwZj4WEdsAvwA2ycyltexmwLXAE5QVy79/vm2X1kRE7A58Engd8DTwU2BW\nZs7p8nF3AH4IvBs4BFgIHAq8PDNXRMRLKbdiegvwe+DMzDyn7rs5MBvYHXgUODkzL6qxzwKvzsz9\nW471l8BVwKcy8/PdPC+p2xwelYCI2ALYETgV+APwn8BHWfmos6MpXzCvA7YCxgBn1n3/hpKw7QZs\nDWwB/OMqjvMC4AfAb4E9TNg0XCLiQODfgCuAlwIvpPQ0f6n+EdJNuwE/yszrKH8kzQQuAjapfyBd\nRbkB+guAtwOfjYg31n0vpDy5ZgKwP3BmROzc30EiYs9a19EmbBoN1uab62qEioibgB8BfwO8Avgx\n8P7MvC8i1qEkVh+m9FTNbtv3NcAXgNcCvwRmZOZ3a+w+4AbgXcA3MvMjLbs+Rvki2LNvQ2Z+tSV+\nFHB8Zj5Q6/og5QsFyo2ZL8rM/66xTwM31Rs3t7ZtAvB94CfAoZn5VIcfjTQoImJDynXyocz8t5bQ\ntyLiEeC6iLgcOBbYNjPfXfcbQ+k5/khmXhsRHwGOp/yh8sO6fVFE7AqcV8vuDOyXmTe1HGcR8NqI\neDFAZvYAp9Rj7Ez5w+jjmfk0sCAi3gD8NiI2BvatbeoBbq/tPITSO956jvsCXwEOzsyrnv+nJg0/\ne9o0Uk0F3knpARgDnFi3f4Ty1/UUYDLwhr4dImITSlL2DWBLyg2TL4uIbVvqnVjrnNF6sHqz5Q8B\n5wDHANPq0CYRsRHlEWcvjoifRcQiSk/ag3X3ScDdrdUBGwMvadm2FXAzcB/lS8SETcPpjcBGwB8N\ng2bmjZT/t/cCLgX2rskSwC7AWOCGiHg35brcl/L/+r3A11uqmgR8k3K9/ajtMN+gXA8LgbdExOER\nsX6N7QgsoPSgLYqI/wZ2zsyHgVcCyzPz3tYm12M9o86X+yZwuAmbRhOTNo1Ul2XmLzLzUeBblH+s\nAQ4A/iUz78vM31HmmfXZG3goM8/NzKfqX/ZzKHNl+lyZmY/3NyyZmVdQkrrvUnrqfhoROwGb1yLv\nB95GSRa3pgwlQfnyW9ZSVd/r8S3bvk/pdXgL8GcD+wikrpkAPJyZy1cRXwS8KDN/DvwM+Nu6/UDg\nitoDdjhlsc6C2ut1IrBTyx9JK4DLM3NZ+x8p9fp8L/B6yry0vwdujoj1KL12u1GmEEykXL9fiIg3\nU661x9vauoxnX2tvoPQi/hdwWO0dlEYFkzYNtSfpf1h+PcpwZ5/ftLxezsr/V18E/Koldl/L64nA\nqyLikb4fyjy0l7aUWbS6xtWFBf9D+UL6V+BjLe36XGY+WP/iP5XSwwDlS2PDlmr6vkCWtmw7JzP3\npCSE34yIcatrh9Rli4EJEbHBKuIvY+W1cgnw3ppQvZvS+wbleju15Vp7COit+wI8UnuwVykz76ZM\nF3gtsA1l/toTwJLMnJmZT2bmfwBXUhLHZUD7tTOeZ19r61KSvn2BnYCPr64NUpOYtGmo/YqV/6gD\nzww/TgAeGMD+v27bv3UI8kHg1szcrO+HMmxyXEuZfpdLR8TrI+LXLUM0UIZ7NsvM31CeTzu2JbYu\nZdgWyoTpaK0OeKS2tc/59feHgU2Bf1n1KUpd9yPgd8BB7YGIeDtlvua1ddPXKEnQO4HFmflfdfuD\nwLS2621HyrAnrOJaq8f4x4g4t+99Zj5e69uMMty5XkSs27JL3/W2ENggIia2Vsezpyf8qPb+/Ro4\nDDglIt666o9Cag6TNg21r1NWgm0LEBF/CpwN3JWZ9wxg/0uBYyJi24jYFDi5JfYdYFJETI2IdSNi\nO+A2VvaIrc7PKF8Mn6m/Xwh8ELiuxr8MfCoiXlxvOfApyrwcgMuAD0fE5NqmUyjDQivaD1KHZacC\n74+I9w+gXdKgqz1gHwXOqvPJNo2I8RHxLkrP2icyc3Et+1vKiudZrOxlgzLJ/4SI+LOIWKcuvJlH\nGcJ8LvOA90XE6wAiYi9K8vVD4HuUHrWTImK9umr0ncA3M/MPlCkPM2t7X0cZsv1qfwfJzGsofzB9\nLSJeNPBPSBqZTNo01E4Cvk1ZnbaUMuF4Q8qk54GYTRm2/BHwv5RbcwCQmUuAPSiLFR6m/ON/Xt89\nnFYnM5cB76AMz3ycMox5M2VhApT5OjdQksBfUFamTq/7XgOcQUka76f0sk1fzbFuoySH59b7zElD\nLjO/SfmD5j3A/1F6uo4FjszMf2orfgmlV7s1ObqUcvuNayn/zx8M7F3nmj7Xsa8ETqckYAdR5oe+\nNzN/WXvddqXMd3sIuBw4JjP7VoceAaxP6Zm/Epher6lV+Vit54q23jupcby5rtSm3qDzy5l53zA3\nRRr1IuLLmXnocLdDagKTNkmSpAZweFSSJKkBTNokSZIawKRNkiSpAUzaJEmSGsCkTZIkqQH6e5yQ\nJA2ZiNiGcu+77eqzLodVRHwZGFefjSlJI4Y9bZIkSQ1g0iZJktQADo9KGjQR8RHKI7xeQnm496cz\n81sREcBZwJuAcZQHfB+XmTf1U8cqy7YMpX4aOB6YC7wK+HpmntxSx78Bv87MYwbQ5r2AfwT+P8pj\nlcawmoedS9JwsadN0qCIiB0oz2o9AdiW8mzKr0XEBOAa4DfA64AplGe3fqmfOsYMsOzbgZ0oydtX\ngQNa6tgE2JtVPES87XjbURK1y4DXAv9NeRanJI04Jm2SBss29ff9mfl/wJnAO4CllAeLH5uZ/52Z\nP6Mkd6+MiPXb6hg/wLJnZ+bCzLyH8kDx7SJi+xp7J/Cr53iIeJ8PALdn5swsPgP8Z6cnLklDwaRN\n0mC5HpgP3BERC4CZwC8y8zHgi8ABEfGliLgZ+FbdZ93WCjooe2/LPr8A/oOVvW3vpSRyA/Eq4M62\nbSZtkkYkkzZJgyIzlwFvAN5CGeL8W+C/IuJNwO2UXq17gc8Bh/RXR0RsPMCyj7e9vwx4T0RsAfwV\nA0/aeilz2FotH+C+kjSkXIggaVBExBuAt2fmZ4F/j4gTgQXAXwKvAP4kM5+sZT9ad2tPmN7eQdlW\n3wA+D/wd8NMO7vf2U+Cv27btCPx6gPtL0pAxaZM0WJYBn4yI3wDfAV5Dmef2NGUV6P4RcQulN+4f\n6j5j2+r4VQdln5GZD0fE9ZSVq5/qoM1fAo6NiNOBLwPvAnYBvtlBHZI0JBwelTQoMvMnlKHMo4Cf\nA18APpGZp1JWeZ5F6Xk7AfgoZRhySlsd8wZath9XABsAX+ugzb8A9qw/d1GGdr880P0laSiN6e31\ndkSSmi8ijgf2ysy/Gu62SFI3ODwqqdEi4tXAn1OGRqe1bB8HbLaaXXszc3GXmydJg8akTVLT/Tnl\n3m5XZOa/tWzflzJkuipPUObPSVIjODwqSZLUAC5EkCRJagCTNkmSpAYwaZMkSWoAkzZJkqQGMGmT\nJElqAJM2SZKkBvj/AS6V38rpOIvKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116bf3208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#bar plot of gender and salary \n",
    "fig=plt.figure(figsize=[8,5])\n",
    "ax = fig.add_subplot(111)\n",
    "sns.countplot(data=df_employed_nod, x = 'salary_d', hue= 'GENDER', palette=\"muted\", ax=ax)\n",
    "sns.despine()\n",
    "plt.title('Gender Pay Gap')\n",
    "ax.set_xticklabels(['Under $60K', 'Over $60K'])\n",
    "lgd=ax.legend(['female', 'male'], bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.tight_layout\n",
    "#plt.savefig('./../results/gendersalary.png',bbox_extra_artists=(lgd,), bbox_inches='tight', dpi = 150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious from the plot above that there are much more men making more than $60k a year compared than women. We have learned from the EDA notebook that the gender pay gap exists and did not improve over the years from 2003 to 2013. This is another quick look at it. Please find the EDA notebook if you are looking for more details on this matter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the numeric columns and assign the rest of the feature columns to categoric columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric = ['AGE']\n",
    "feature_df = df_employed_nod.drop(['salary_d'],axis=1)\n",
    "categoric = feature_df.columns.difference(numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I look into the numeric column and check its distribution. The age profile in this data set is not really normal distribution. It is caused by the nature human behavior, people usually do not start working after college, some people tend to stay in the work force longer than the other. So we see a jump at 25 and a long tail after 60. The good news is that our survey data is large (391,000 entries), the null hypothesis will work here according to the central limit theorem (CLT). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFgCAYAAABNIolGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiFe//AYjG+2Fb54KwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11566a390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-values from t-tests\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>P_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attribute  P_value\n",
       "0       AGE      0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_vals = pd.DataFrame(columns=['Attribute', 'P_value'])\n",
    "\n",
    "for col in numeric:\n",
    "   \n",
    "    # Plotting distributions of each column\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(121)\n",
    "    sns.distplot(df_employed_nod[col], color='magenta')\n",
    "    plt.title('Distribution of {}'.format(col))\n",
    "\n",
    "    # Plotting distributions of each column by income level\n",
    "    plt.subplot(122)\n",
    "    g = sns.boxplot(x='salary_d', y=col, data=df_employed_nod, palette='bright')\n",
    "    g.set_xticklabels(['Under $60K', 'Over $60K'])\n",
    "    plt.title('Distribution of income by {}'.format(col))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculating pvalues from t-test\n",
    "    t_val, p_val = ttest_ind(df_employed_nod[df_employed_nod['salary_d']==0][col],\n",
    "                                df_employed_nod[df_employed_nod['salary_d']==1][col])\n",
    "    p_vals = p_vals.append({'Attribute':col, 'P_value':float(p_val)}, ignore_index=True)\n",
    "    \n",
    "\n",
    "# Printing p-values of t-tests, sorted by p-values\n",
    "print('P-values from t-tests')\n",
    "p_vals.sort_values('P_value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p_value for the numeric columns are practically zero, which means age is statistically significant to determine the salary level of an individual. We will keep it as it is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepare the categorical feature columns for classification. We are going to convert these categorical variable into dummy/indicator variables, calling the get_dummies function by pandas (thank you Pandas!). Note the drop_first parameter was set to true to avoid collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>salary_d</th>\n",
       "      <th>ACTCAP_1.0</th>\n",
       "      <th>ACTDED_1.0</th>\n",
       "      <th>ACTMGT_1.0</th>\n",
       "      <th>ACTRD_1.0</th>\n",
       "      <th>ACTRDT_1.0</th>\n",
       "      <th>ACTRES_1.0</th>\n",
       "      <th>ACTTCH_1.0</th>\n",
       "      <th>BTHUS_1</th>\n",
       "      <th>...</th>\n",
       "      <th>WASEC_14.0</th>\n",
       "      <th>WASEC_15.0</th>\n",
       "      <th>WKSWKGR_2.0</th>\n",
       "      <th>WKSWKGR_3.0</th>\n",
       "      <th>WKSWKGR_4.0</th>\n",
       "      <th>WKTRNI_1.0</th>\n",
       "      <th>YEAR_2006</th>\n",
       "      <th>YEAR_2008</th>\n",
       "      <th>YEAR_2010</th>\n",
       "      <th>YEAR_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE salary_d  ACTCAP_1.0  ACTDED_1.0  ACTMGT_1.0  ACTRD_1.0  ACTRDT_1.0  \\\n",
       "0   47      0.0           0           0           0          0           1   \n",
       "1   66      1.0           0           1           1          1           1   \n",
       "2   60      1.0           1           0           1          0           0   \n",
       "3   30      1.0           0           1           0          1           1   \n",
       "5   51      1.0           0           0           1          0           0   \n",
       "\n",
       "   ACTRES_1.0  ACTTCH_1.0  BTHUS_1    ...      WASEC_14.0  WASEC_15.0  \\\n",
       "0           0           1        0    ...               0           0   \n",
       "1           0           0        1    ...               0           0   \n",
       "2           0           0        1    ...               0           0   \n",
       "3           1           0        1    ...               0           0   \n",
       "5           0           0        1    ...               0           0   \n",
       "\n",
       "   WKSWKGR_2.0  WKSWKGR_3.0  WKSWKGR_4.0  WKTRNI_1.0  YEAR_2006  YEAR_2008  \\\n",
       "0            0            1            0           1          0          0   \n",
       "1            0            0            1           0          0          0   \n",
       "2            0            0            1           1          0          0   \n",
       "3            0            0            1           1          0          0   \n",
       "5            0            0            1           1          0          0   \n",
       "\n",
       "   YEAR_2010  YEAR_2013  \n",
       "0          0          0  \n",
       "1          0          0  \n",
       "2          0          0  \n",
       "3          0          0  \n",
       "5          0          0  \n",
       "\n",
       "[5 rows x 166 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = df_employed_nod.drop(['salary_d'],axis=1)\n",
    "categoric = feature_df.columns.difference(numeric)\n",
    "df_employed_nod_sig = pd.get_dummies(data=df_employed_nod, columns=categoric, drop_first=True)\n",
    "df_employed_nod_sig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we go through all the dummied categorical variables and do the chi-squared test with the salary level column. The purpose is to filter out attributes that statistically insignificant. This will simplify our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-values from Chi-Squared Contingency Tests\n",
      "          Attribute   P_value\n",
      "115      SAMPLE_801  0.851496\n",
      "25      HD03Y5_1956  0.427363\n",
      "76    NDGMED_611995  0.284468\n",
      "87   NOCPR_393995.0  0.108034\n",
      "89   NOCPR_432360.0  0.104620\n",
      "145      WASEC_13.0  0.071465\n",
      "137      WASCSM_2.0  0.071465\n",
      "153       WASEC_7.0  0.064534\n",
      "26      HD03Y5_1961  0.060264\n",
      "3        ACTRDT_1.0  0.039083\n",
      "info of df before deleting insignificant attributes:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 333044 entries, 0 to 478746\n",
      "Columns: 166 entries, AGE to YEAR_2013\n",
      "dtypes: category(1), int64(1), uint8(164)\n",
      "memory usage: 67.5 MB\n",
      "None\n",
      "info of df after:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 333044 entries, 0 to 478746\n",
      "Columns: 152 entries, AGE to YEAR_2013\n",
      "dtypes: category(1), int64(1), uint8(150)\n",
      "memory usage: 63.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "p_vals_cate = pd.DataFrame(columns=['Attribute', 'P_value'])\n",
    "categoric = df_employed_nod_sig.columns.difference(['AGE','salary_d'])\n",
    "p_large = []\n",
    "\n",
    "for col in categoric:\n",
    "    # Creating cross tabulated data for Chi-square test\n",
    "    counttable = pd.crosstab(df_employed_nod_sig[col], df_employed_nod_sig['salary_d'])\n",
    "    chi2, p, dof, ex = chi2_contingency(counttable, correction=False)\n",
    "    p_vals_cate = p_vals_cate.append({'Attribute':col, 'P_value':float(p)}, ignore_index=True)\n",
    "    if p>0.01:\n",
    "         p_large.append(col)\n",
    "    \n",
    "# Printing p-values of Chi-squared tests, sorted by p-values\n",
    "print('P-values from Chi-Squared Contingency Tests')\n",
    "print(p_vals_cate.sort_values('P_value', ascending=False).head(10))\n",
    "\n",
    "print('info of df before deleting insignificant attributes:')\n",
    "print(df_employed_nod_sig.info())\n",
    "\n",
    "df_employed_nod_sig_2  = df_employed_nod_sig.drop(p_large, axis=1)\n",
    "\n",
    "print('info of df after:')\n",
    "print(df_employed_nod_sig_2.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, fourteen columns are deleted because their Chi-Squared cntingency tests p-value is larger than defined significance level (0.01). These statistically insignificant features include certain part of the survey, some secondary job activities, certain some majors and etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the target coloumn and the feature columns, using the results from the previous preparation. Scikit-learn's train_test_split makes it easy to separate the data into training and test data. \n",
    "\n",
    "Before we proceed to the next step, recall that the distribution of the salary level: there are more entries with higher than 60k salary level. The inbalance will cause under sampling. To avoid this, use the RandomUnderSampler function to ensure we are choosing the same amount of entries from both target classes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Training Set Percent Under $60,000: 28.7%\n",
      "Resampled Training Set Percent Under $60,000: 50.0%\n"
     ]
    }
   ],
   "source": [
    "df_employed_nod_sig_3 = df_employed_nod_sig_2#.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Identify variables\n",
    "X = df_employed_nod_sig_3.drop('salary_d', axis=1)\n",
    "y = df_employed_nod_sig_3.salary_d\n",
    "\n",
    "# Splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=41)\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=41)\n",
    "X_rus, y_rus = rus.fit_sample(X=X_train, y=y_train)\n",
    "X_rus_test, y_rus_test = rus.fit_sample(X=X_test, y=y_test)\n",
    "\n",
    "print('Raw Training Set Percent Under $60,000: {:.1f}%'.format(\n",
    "    len(y_train[y_train == 0])/len(y_train)*100))\n",
    "print('Resampled Training Set Percent Under $60,000: {}%'.format(\n",
    "    len(y_rus[y_rus == 0])/len(y_rus)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data prepared, we will proceed to test with several classification models. I will find the accuracy score using logistic regression, random forest classifier, KNN, and AdaBoost classifier. For each model, the cross validated grid search will be called find the best parameters. Then the found parameters are fed back into the model for prediction of the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression parameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiate list to store the training and testing scores for classification models\n",
    "score_train = []\n",
    "score_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.78095902354\n",
      "Best Parameters: {'C': 10, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "parameters = [{'C':[0.1,1,10,100], 'solver':['lbfgs'], 'fit_intercept':[True]},\n",
    "              {'C':[0.1,1,10,100], 'solver':['liblinear'], 'penalty':['l1', 'l2'], 'fit_intercept':[True]}]\n",
    "# Instantiating and fitting model through grid search\n",
    "grid_logR = GridSearchCV(clf, param_grid=parameters)\n",
    "grid_logR.fit(X_rus, y_rus)\n",
    "\n",
    "# Printing the best score from the model\n",
    "print('Best Score:', grid_logR.best_score_)\n",
    "\n",
    "# Saving and printing the best parameters from the model\n",
    "best_params = grid_logR.best_params_\n",
    "print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy Scores - Training Set: 0.78174(+/- 0.01)\n",
      "Cross Validation Accuracy Scores - Test Set: 0.81533(+/- 0.00)\n",
      "Confusion matrix on the test data:\n",
      "[[ 51466  14097]\n",
      " [ 37430 130138]]\n",
      "Classification report on the test data:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.58      0.78      0.67     65563\n",
      "        1.0       0.90      0.78      0.83    167568\n",
      "\n",
      "avg / total       0.81      0.78      0.79    233131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initiate a instance for classifier\n",
    "clf = LogisticRegression(**best_params)\n",
    "#clf = RandomForestClassifier(n_estimators=50, max_depth=100)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_rus, y_rus)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "scores_LR_train = cross_val_score(clf, X_rus, y_rus, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Training Set: {:.5f}(+/- {:.2f})'.format(scores_LR_train.mean(), \n",
    "                                                                                 scores_LR_train.std()*2))\n",
    "scores_LR_test = cross_val_score(clf, X_test, y_test, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Test Set: {:.5f}(+/- {:.2f})'.format(scores_LR_test.mean(), \n",
    "                                                                            scores_LR_test.std()*2))\n",
    "\n",
    "score_train.append(scores_LR_train.mean())\n",
    "score_test.append(scores_LR_test.mean())\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print('Confusion matrix on the test data:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Classification report on the test data:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking the logistic regression coefficient, we can take a glance at the features that contribute most to the classification of our target.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features with the most impact on higher income levels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Coef</th>\n",
       "      <th>Odds_Ratios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EMSIZE_8.0</td>\n",
       "      <td>2.049162</td>\n",
       "      <td>7.761397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DGRDG_4</td>\n",
       "      <td>2.011932</td>\n",
       "      <td>7.477754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EMSIZE_7.0</td>\n",
       "      <td>1.726152</td>\n",
       "      <td>5.618988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DGRDG_3</td>\n",
       "      <td>1.691709</td>\n",
       "      <td>5.428751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EMSIZE_6.0</td>\n",
       "      <td>1.556426</td>\n",
       "      <td>4.741845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Attribute      Coef  Odds_Ratios\n",
       "21  EMSIZE_8.0  2.049162     7.761397\n",
       "11     DGRDG_4  2.011932     7.477754\n",
       "20  EMSIZE_7.0  1.726152     5.618988\n",
       "10     DGRDG_3  1.691709     5.428751\n",
       "19  EMSIZE_6.0  1.556426     4.741845"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame with Features and Logistic Regression Coefficients\n",
    "coefs_lg = pd.concat([pd.DataFrame(X_train.columns), pd.DataFrame(np.transpose(clf.coef_))], axis=1)\n",
    "coefs_lg.columns = ['Attribute', 'Coef']\n",
    "# Calculating exponentiated coefficients for interpretation\n",
    "coefs_lg['Odds_Ratios'] = np.exp(coefs_lg['Coef'])\n",
    "print('\\nFeatures with the most impact on higher income levels')\n",
    "coefs_lg.sort_values('Odds_Ratios', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is insightful! We found:\n",
    "\n",
    "1. professional or doctorate degrees both play a important positive role in being classified into the higher salary level. \n",
    "\n",
    "2. The size of the employer is another important attribute: Chances are you will get a better pay working for a large coorporate employer (large than 5000 employees). \n",
    "\n",
    "3. The last feature among the top five positive impact is the principal job field. Being the science and engineering manager is advantageous to receiving a higher salary, which is reasonable and inspiring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classifier parameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.78385353095\n",
      "Best Parameters: {'max_depth': 100, 'max_features': 10, 'n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param_grid = {\"n_estimators\": [30, 50, 75],\n",
    "              \"max_features\": [10, 30, 50],\n",
    "              \"max_depth\": [10, 100, 300]\n",
    "              }\n",
    "\n",
    "grid_rf = GridSearchCV(rf, param_grid=param_grid, cv=5)\n",
    "grid_rf.fit(X_rus, y_rus)\n",
    "\n",
    "# Printing the best score from the model\n",
    "print('Best Score:', grid_rf.best_score_)\n",
    "\n",
    "# Saving and printing the best parameters from the model\n",
    "best_params = grid_rf.best_params_\n",
    "print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy Scores - Training Set: 0.78405(+/- 0.01)\n",
      "Cross Validation Accuracy Scores - Test Set: 0.82578(+/- 0.00)\n",
      "Confusion matrix on the test data:\n",
      "[[ 51336  14227]\n",
      " [ 35302 132266]]\n",
      "Classification report on the test data:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.59      0.78      0.67     65563\n",
      "        1.0       0.90      0.79      0.84    167568\n",
      "\n",
      "avg / total       0.82      0.79      0.80    233131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initiate a instance for classifier\n",
    "rf = RandomForestClassifier(**best_params)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf.fit(X_rus, y_rus)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "scores_rf_train = cross_val_score(rf, X_rus, y_rus, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Training Set: {:.5f}(+/- {:.2f})'.format(scores_rf_train.mean(), \n",
    "                                                                                 scores_rf_train.std()*2))\n",
    "scores_rf_test = cross_val_score(rf, X_test, y_test, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Test Set: {:.5f}(+/- {:.2f})'.format(scores_rf_test.mean(), \n",
    "                                                                                 scores_rf_test.std()*2))\n",
    "\n",
    "score_train.append(scores_rf_train.mean())\n",
    "score_test.append(scores_rf_test.mean())\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print('Confusion matrix on the test data:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Classification report on the test data:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN parameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.744864864865\n",
      "Best Parameters: {'leaf_size': 50, 'n_neighbors': 15, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "param_grid = {\"n_neighbors\": [5, 10, 15],\n",
    "              \"leaf_size\": [10, 30, 50],\n",
    "              \"weights\": ['uniform', 'distance']\n",
    "              }\n",
    "\n",
    "\n",
    "grid_knn = GridSearchCV(knn, param_grid=param_grid, cv=5)\n",
    "grid_knn.fit(X_rus, y_rus)\n",
    "\n",
    "# Printing the best score from the model\n",
    "print('Best Score:', grid_knn.best_score_)\n",
    "\n",
    "# Saving and printing the best parameters from the model\n",
    "best_params = grid_knn.best_params_\n",
    "print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy Scores - Training Set: 0.74486(+/- 0.00)\n",
      "Cross Validation Accuracy Scores - Test Set: 0.79986(+/- 0.00)\n",
      "Confusion matrix on the test data:\n",
      "[[ 46543  19020]\n",
      " [ 35723 131845]]\n",
      "Classification report on the test data:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      0.71      0.63     65563\n",
      "        1.0       0.87      0.79      0.83    167568\n",
      "\n",
      "avg / total       0.79      0.77      0.77    233131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initiate a instance for classifier\n",
    "knn = KNeighborsClassifier(**best_params)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_rus, y_rus)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "scores_knn_train = cross_val_score(knn, X_rus, y_rus, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Training Set: {:.5f}(+/- {:.2f})'.format(scores_knn_train.mean(), \n",
    "                                                                                 scores_knn_train.std()*2))\n",
    "scores_knn_test = cross_val_score(knn, X_test, y_test, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Test Set: {:.5f}(+/- {:.2f})'.format(scores_knn_test.mean(), \n",
    "                                                                                 scores_knn_test.std()*2))\n",
    "\n",
    "score_train.append(scores_knn_train.mean())\n",
    "score_test.append(scores_knn_test.mean())\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print('Confusion matrix on the test data:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Classification report on the test data:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost classifier parameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.778308631212\n",
      "Best Parameters: {'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "              \"n_estimators\": [10, 100, 200]\n",
    "             }\n",
    "\n",
    "\n",
    "ABC = AdaBoostClassifier()\n",
    "\n",
    "# run grid search\n",
    "grid_ab = GridSearchCV(ABC, param_grid=param_grid)\n",
    "\n",
    "grid_ab.fit(X_rus, y_rus)\n",
    "\n",
    "# Printing the best score from the model\n",
    "print('Best Score:', grid_ab.best_score_)\n",
    "\n",
    "# Saving and printing the best parameters from the model\n",
    "best_params = grid_ab.best_params_\n",
    "print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy Scores - Training Set: 0.77932(+/- 0.01)\n",
      "Cross Validation Accuracy Scores - Test Set: 0.81329(+/- 0.00)\n",
      "Confusion matrix on the test data:\n",
      "[[ 51145  14418]\n",
      " [ 37346 130222]]\n",
      "Classification report on the test data:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.58      0.78      0.66     65563\n",
      "        1.0       0.90      0.78      0.83    167568\n",
      "\n",
      "avg / total       0.81      0.78      0.79    233131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initiate a instance for classifier\n",
    "\n",
    "ab = AdaBoostClassifier(**best_params)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "ab.fit(X_rus, y_rus)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = ab.predict(X_test)\n",
    "\n",
    "scores_ab_train = cross_val_score(ab, X_rus, y_rus, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Training Set: {:.5f}(+/- {:.2f})'.format(scores_ab_train.mean(), \n",
    "                                                                                 scores_ab_train.std()*2))\n",
    "scores_ab_test = cross_val_score(ab, X_test, y_test, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Test Set: {:.5f}(+/- {:.2f})'.format(scores_ab_test.mean(), \n",
    "                                                                                 scores_ab_test.std()*2))\n",
    "\n",
    "score_train.append(scores_ab_train.mean())\n",
    "score_test.append(scores_ab_test.mean())\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print('Confusion matrix on the test data:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Classification report on the test data:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-e51dfd6c5ef9>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-e51dfd6c5ef9>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    'Accuracy score on test': score_test\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "models = ['Logistic Regression', 'Random Forest Classifier', 'KNN', 'AdaBoost']\n",
    "model_comp = pd.DataFrame(\n",
    "    {'models': models,\n",
    "     'Accuracy score on train': score_train\n",
    "     'Accuracy score on test': score_test\n",
    "    })\n",
    "print(model_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare ROC curve plot\n",
    "y_pred_prob_lg = clf.predict_proba(X_test)[:,1]\n",
    "y_pred_prob_rf = rf.predict_proba(X_test)[:,1]\n",
    "y_pred_prob_knn = knn.predict_proba(X_test)[:,1]\n",
    "y_pred_prob_ab = ab.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr_lg, tpr_lg, thresholds_lg = roc_curve(y_test, y_pred_prob_lg)\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_pred_prob_rf)\n",
    "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, y_pred_prob_knn)\n",
    "fpr_ab, tpr_ab, thresholds_ab = roc_curve(y_test, y_pred_prob_ab)\n",
    "\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_lg, tpr_lg, 'red', label='Logistic regression')\n",
    "plt.plot(fpr_rf, tpr_rf, 'blue', label='Random Forest Classifier')\n",
    "plt.plot(fpr_knn, tpr_knn, 'green', label='KNN')\n",
    "plt.plot(fpr_ab, tpr_ab, 'yellow', label='Adaboost Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the salary level among women employees in 2013:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now a good time to run the model with the latest data for women employees. Nevertheless, the focus of this project is women in STEM workforce and we can get the most related insight using the most recent data. So next, we choose the women and year 2013 in the survey data and use logistic regression to predict the salary level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employed_nod_sig_3 = df_employed_nod_sig_2\n",
    "# Identify variables\n",
    "X = df_employed_nod_sig_3[(df_employed_nod_sig_3['GENDER_2']==0)&(df_employed_nod_sig_3['YEAR_2013']==1)].drop('salary_d', axis=1)\n",
    "y = df_employed_nod_sig_3[df_employed_nod_sig_3['GENDER_2']==0&(df_employed_nod_sig_3['YEAR_2013']==1)].salary_d\n",
    "\n",
    "# Splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=41)\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=41)\n",
    "X_rus, y_rus = rus.fit_sample(X=X_train, y=y_train)\n",
    "\n",
    "print('Raw Training Set Percent Under $60,000: {:.1f}%'.format(\n",
    "    len(y_train[y_train == 0])/len(y_train)*100))\n",
    "print('Resampled Training Set Percent Under $60,000: {}%'.format(\n",
    "    len(y_rus[y_rus == 0])/len(y_rus)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "parameters = [{'C':[0.1,1,10,100], 'solver':['lbfgs'], 'fit_intercept':[True]},\n",
    "              {'C':[0.1,1,10,100], 'solver':['liblinear'], 'penalty':['l1', 'l2'], 'fit_intercept':[True]}]\n",
    "# Instantiating and fitting model through grid search\n",
    "grid_logR = GridSearchCV(clf, param_grid=parameters)\n",
    "grid_logR.fit(X_rus, y_rus)\n",
    "\n",
    "# Printing the best score from the model\n",
    "print('Best Score:', grid_logR.best_score_)\n",
    "\n",
    "# Saving and printing the best parameters from the model\n",
    "best_params = grid_logR.best_params_\n",
    "print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate a instance for classifier\n",
    "clf = LogisticRegression(**best_params)\n",
    "#clf = RandomForestClassifier(n_estimators=50, max_depth=100)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_rus, y_rus)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "scores_LR_train = cross_val_score(clf, X_rus, y_rus, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Training Set: {:.5f}(+/- {:.2f})'.format(scores_LR_train.mean(), \n",
    "                                                                                 scores_LR_train.std()*2))\n",
    "scores_LR_test = cross_val_score(clf, X_test, y_test, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Test Set: {:.5f}(+/- {:.2f})'.format(scores_LR_test.mean(), \n",
    "                                                                                 scores_LR_test.std()*2))\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print('Confusion matrix on the test data:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Classification report on the test data:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predict the Principal Job Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are a college student, what would you expect when you go to the workforce? Are you going to work on major related fields? Here we are going to answer this question by using machine learning models on the pre-employment portion of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all the column names in the data frame\n",
    "df_employed_clf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are planning to predict the field of work for an individual looking for a job, a soon-to-be college graduate for example. This indicates that we don't have any information about the jobs for that person. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use only columns that are pre-employment. \n",
    "# Choose the target column 'NOCPRMG'\n",
    "\n",
    "df_employed_nod = df_employed_clf[['YEAR', 'SAMPLE', 'SURID', 'AGE', 'GENDER', 'MINRTY', 'RACETH',\n",
    "       'BTHUS', 'CTZUSIN', 'NBAMED', 'NBAMEMG', 'DGRDG', 'HD03Y5', 'NDGMED',\n",
    "       'NDGMEMG', 'NOCPRMG']]\n",
    "\n",
    "\n",
    "# numeric columns\n",
    "numeric = ['AGE']\n",
    "# categoric columns\n",
    "categoric = df_employed_nod.drop(['NOCPRMG'],axis=1).columns.difference(numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change categorical features to dummied columns\n",
    "df_employed_nod_sig = pd.get_dummies(data=df_employed_nod, columns=categoric, drop_first=True)\n",
    "df_employed_nod_sig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take NOCPRMG = 2 as a first look at the problem. The target column indicates whether the principal job field of the individual is biological, agricultural and other life sciences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to find for a certain type job field only. \n",
    "# NOCPRMG = 1, Computer and mathematical scientists\n",
    "# NOCPRMG = 2, Biological, agricultural and other life scientists\n",
    "# NOCPRMG = 3, Physical and related scientists\n",
    "# NOCPRMG = 4, Social and related scientists\n",
    "# NOCPRMG = 5, Engineers\n",
    "# NOCPRMG = 6, Science and engineering related occupations\n",
    "# NOCPRMG = 7, Non-science and engineering occupations\n",
    "\n",
    "def job_fd(ls):\n",
    "    new_s = np.empty(len(ls))\n",
    "    for i,s in enumerate(ls):\n",
    "        if s==2:\n",
    "            new_s[i] = 1\n",
    "        else:\n",
    "            new_s[i] = 0\n",
    "    return new_s\n",
    "\n",
    "rd = job_fd(df_employed_nod_sig['NOCPRMG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_employed_nod_sig_3 = df_employed_nod_sig#.sample(frac=1, random_state=42)\n",
    "# Identify variables\n",
    "X = df_employed_nod_sig_3.drop('NOCPRMG', axis=1)\n",
    "y = rd\n",
    "\n",
    "# Splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=41)\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=41)\n",
    "X_rus, y_rus = rus.fit_sample(X=X_train, y=y_train)\n",
    "X_rus_test, y_rus_test = rus.fit_sample(X=X_test, y=y_test)\n",
    "\n",
    "print('Raw Training Set Percent with job field 2: {:.1f}%'.format(\n",
    "    len(y_train[y_train == 1])/len(y_train)*100))\n",
    "print('Resampled Training Set Percent with job field 2: {:.1f}%'.format(\n",
    "    len(y_rus[y_rus == 1])/len(y_rus)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "parameters = [{'C':[0.1,1,10,100], 'solver':['lbfgs'], 'fit_intercept':[True]},\n",
    "              {'C':[0.1,1,10,100], 'solver':['liblinear'], 'penalty':['l1', 'l2'], 'fit_intercept':[True]}]\n",
    "# Instantiating and fitting model through grid search\n",
    "grid_logR = GridSearchCV(clf, param_grid=parameters)\n",
    "grid_logR.fit(X_rus, y_rus)\n",
    "\n",
    "# Printing the best score from the model\n",
    "print('Best Score:', grid_logR.best_score_)\n",
    "\n",
    "# Saving and printing the best parameters from the model\n",
    "best_params = grid_logR.best_params_\n",
    "print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate a instance for classifier\n",
    "clf = LogisticRegression(**best_params)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_rus, y_rus)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = clf.predict(X_rus_test)\n",
    "\n",
    "scores_LR_train = cross_val_score(clf, X_rus, y_rus, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Training Set: {:.5f}(+/- {:.2f})'.format(scores_LR_train.mean(), \n",
    "                                                                                 scores_LR_train.std()*2))\n",
    "scores_LR_test = cross_val_score(clf, X_rus_test, y_rus_test, cv=5)\n",
    "print('Cross Validation Accuracy Scores - Test Set: {:.5f}(+/- {:.2f})'.format(scores_LR_test.mean(), \n",
    "                                                                                 scores_LR_test.std()*2))\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print('Confusion matrix on the test data:')\n",
    "print(confusion_matrix(y_rus_test, y_pred))\n",
    "print('Classification report on the test data:')\n",
    "print(classification_report(y_rus_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very well predicted! We see there is a 0.86 accuracy score using logistic regression deciding whether an individual is going into the job field of biology and life sciences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating Data Frame with Features and Logistic Regression Coefficients\n",
    "coefs_lg = pd.concat([pd.DataFrame(X_train.columns), pd.DataFrame(np.transpose(clf.coef_))], axis=1)\n",
    "coefs_lg.columns = ['Attribute', 'Coef']\n",
    "# Calculating exponentiated coefficients for interpretation\n",
    "coefs_lg['Odds_Ratios'] = np.exp(coefs_lg['Coef'])\n",
    "print('\\nFeatures with the most impact on job field of biological, agricultural and other life sciences: ')\n",
    "coefs_lg.sort_values('Odds_Ratios', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression also conveniently tells us the features with most impact on being in the job field: related field of major of the highest degree and the doctorate degree. It seems that students majored in life science with a high level degree is most likely to stay in the same topic when going into the workforce. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job fields comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we run the same classification on all the job fields and compare the results. It could give us some insight in what fields are most likely to have predictable employee sources. This question is similar to, what fields of majors are more likely to stay in relevent field when entering the workforce? I choose random forest classification to do this job because it gave the best result in the previous salary level classification. Random forest works well with the size and number of features of this survey data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a list contains the name of the work field. \n",
    "score_field_dic = ['Computer and mathematical scientists', 'Biological, agricultural and other life scientists',\n",
    "              'Physical and related scientists', 'Social and related scientists', \n",
    "              'Engineers', 'Science and engineering related occupations',\n",
    "               'Non-science and engineering occupations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to binarize the target column\n",
    "\n",
    "def job_fd(ls, n):\n",
    "    new_s = np.empty(len(ls))\n",
    "    for i,s in enumerate(ls):\n",
    "        if s==n:\n",
    "            new_s[i] = 1\n",
    "        else:\n",
    "            new_s[i] = 0\n",
    "    return new_s\n",
    "\n",
    "rus = RandomUnderSampler(random_state=41)\n",
    "train_score=[]\n",
    "test_score=[]\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    rd = job_fd(df_employed_nod_sig['NOCPRMG'], i+1)\n",
    "    \n",
    "    # Identify variables\n",
    "    X = df_employed_nod_sig_3.drop('NOCPRMG', axis=1)\n",
    "    y = rd\n",
    "\n",
    "    # Splitting into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=41)\n",
    "\n",
    "    X_rus, y_rus = rus.fit_sample(X=X_train, y=y_train)\n",
    "    X_rus_test, y_rus_test = rus.fit_sample(X=X_test, y=y_test)\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    \n",
    "    param_grid = {\"n_estimators\": [30, 50, 75],\n",
    "              \"max_features\": [10, 30, 50],\n",
    "              \"max_depth\": [10, 100]\n",
    "              }\n",
    "\n",
    "    grid_rf = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "    grid_rf.fit(X_rus, y_rus)\n",
    "\n",
    "    best_params = grid_rf.best_params_\n",
    "\n",
    "    #initiate a instance for classifier\n",
    "    rf = RandomForestClassifier(**best_params)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    rf.fit(X_rus, y_rus)\n",
    "\n",
    "    # Predict the labels of the test data: y_pred\n",
    "    y_pred = rf.predict(X_rus_test)\n",
    "\n",
    "    scores_rf_train = cross_val_score(rf, X_rus, y_rus, cv=5)\n",
    "    train_score.append(scores_rf_train.mean())\n",
    "    \n",
    "    scores_rf_test = cross_val_score(rf, X_rus_test, y_rus_test, cv=5)\n",
    "    test_score.append(scores_rf_test.mean())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(\n",
    "    {'Field of Work': score_field_dic,\n",
    "     'Accuracy score on train': train_score,\n",
    "     'Accuracy score on test': test_score\n",
    "    })\n",
    "\n",
    "score_df.sort_values('Accuracy score on test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Wow, some insights to discover here:\n",
    "   1. The random forest classification model does a good job! It predicts the fields of work with accuracy score ranging from 0.72 to 0.91.\n",
    "   2. Social scientists, physical scientists and engineers are top 3 most predictable field of work in this survey. From the logistic regression coefficient results from the biogical and life scientists field, we could say the mojor field of the highest degree is the most important deciding factor in going into the related job fields. It looks like these top three fields of work have the most predictable human resources. Students majoring in these fields are more likely to enter related workforce. \n",
    "   3. Non-science and engineering occupations are least accurately predicted. My thought on this people majoring STEM could go to non STEM job fields for many reasons: change of interest, financial pressure, and career choices, to name a few. The occurance of these could be more random and less predictable than the rest of the job fields. It causes a lower accuracy score. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I explored several classification models on the higher education SESTAT survey data, the leading surveys for studying the science and engineering (STEM) workforce. \n",
    "\n",
    "I prepared the target, numeric, and catagorical columns for the machine learning models. Statistical functions were used for feature selections. Then four classification models were picked to fit, cross validate and predict the salary level of the entries. I used accuracy scores and ROC curves to compare these methonds. It seems random forest classifier performed best. With the vital geographic location data missing (for privacy reasons), we still got accuracy scores as high as 0.82. \n",
    "\n",
    "Next, the question of job field was answered. Which job field do you expect when you go to the workforce? The logistic regression coefficients help to understand the field of major is an important factor in anaswering the question. Each job field appeared was predicted with the pre-employment portion of the data. The classification models does a great job predicting the job field in general. The results find some fields are more accurately predicted than others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
